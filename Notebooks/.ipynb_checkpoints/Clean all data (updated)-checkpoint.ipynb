{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing how millennial women spend money via Refinery29\n",
    "**Objective**   \n",
    "Analyze how millennial women spend their time and money using NLP. Build a recommender that takes in user input and selects 3 Refinery29 Money Diaries that are similar to the user.  \n",
    "\n",
    "**Data**   \n",
    "This data was scraped from the [Refinery29 Money Diaries](https://refinery29.com/en-us/money-diary) from January 18, 2019-June 3, 2020.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load packages.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:02.414482Z",
     "start_time": "2020-08-20T17:56:02.410255Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load in pickled DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:04.051455Z",
     "start_time": "2020-08-20T17:56:03.835572Z"
    }
   },
   "outputs": [],
   "source": [
    "diarist_df = pickle.load(open(\"diarist_df.pkl\",\"rb\"))\n",
    "text_df = pickle.load(open(\"text_df.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean diarist_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:04.998260Z",
     "start_time": "2020-08-20T17:56:04.994158Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop blank age values (other articles from money diaries, but aren't diaries)\n",
    "diarist_df = diarist_df[diarist_df.age != 'BLANK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:05.342227Z",
     "start_time": "2020-08-20T17:56:05.339128Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop blank location values \n",
    "diarist_df = diarist_df[diarist_df.location != 'BLANK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:05.692567Z",
     "start_time": "2020-08-20T17:56:05.689178Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop blank occupation values \n",
    "diarist_df = diarist_df[diarist_df.occupation != 'BLANK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:06.328093Z",
     "start_time": "2020-08-20T17:56:06.324080Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create function to clean salaries by removing common characters in salaries\n",
    "def clean_salaries(text):\n",
    "    '''Removes $ , from text'''\n",
    "    text = text.replace('$','')\n",
    "    text = text.replace(',','')\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_salaries(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:06.944247Z",
     "start_time": "2020-08-20T17:56:06.939947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply function to salary column\n",
    "diarist_df['salary'] = diarist_df['salary'].apply(round1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:07.855250Z",
     "start_time": "2020-08-20T17:56:07.807694Z"
    }
   },
   "outputs": [],
   "source": [
    "# Manually fix salaries that aren't just 1 number. Take current salary (no bonuses). If unemployed, put 0.\n",
    "# If range given, take average. If hourly rate given, calculated per year based on 40 hours/week.\n",
    "diarist_df.at[0, 'salary'] = 187000\n",
    "diarist_df.at[2, 'salary'] = 0\n",
    "diarist_df.at[3, 'salary'] = 145500\n",
    "diarist_df.at[10, 'salary'] = 325000\n",
    "diarist_df.at[11, 'salary'] = 128000\n",
    "diarist_df.at[12, 'salary'] = 103500\n",
    "diarist_df.at[13, 'salary'] = 190000\n",
    "diarist_df.at[15, 'salary'] = 0\n",
    "diarist_df.at[26, 'salary'] = 105000\n",
    "diarist_df.at[27, 'salary'] = 230961\n",
    "diarist_df.at[28, 'salary'] = 91000\n",
    "diarist_df.at[30, 'salary'] = 40000\n",
    "diarist_df.at[31, 'salary'] = 78600\n",
    "diarist_df.at[33, 'salary'] = 45500\n",
    "diarist_df.at[36, 'salary'] = 0\n",
    "diarist_df.at[41, 'salary'] = 96000\n",
    "diarist_df.at[42, 'salary'] = 100000\n",
    "diarist_df.at[44, 'salary'] = 105000\n",
    "diarist_df.at[45, 'salary'] = 27246\n",
    "diarist_df.at[47, 'salary'] = 43680\n",
    "diarist_df.at[48, 'salary'] = 50000\n",
    "diarist_df.at[56, 'salary'] = 50000\n",
    "diarist_df.at[57, 'salary'] = 80000\n",
    "diarist_df.at[58, 'salary'] = 0\n",
    "diarist_df.at[68, 'salary'] = 44100\n",
    "diarist_df.at[69, 'salary'] = 66000\n",
    "diarist_df.at[71, 'salary'] = 71000\n",
    "diarist_df.at[77, 'salary'] = 60000\n",
    "diarist_df.at[79, 'salary'] = 28000\n",
    "diarist_df.at[85, 'salary'] = 0\n",
    "diarist_df.at[86, 'salary'] = 34840\n",
    "diarist_df.at[87, 'salary'] = 83000\n",
    "diarist_df.at[88, 'salary'] = 76500\n",
    "diarist_df.at[90, 'salary'] = 86500\n",
    "diarist_df.at[93, 'salary'] = 115000\n",
    "diarist_df.at[94, 'salary'] = 37440\n",
    "diarist_df.at[95, 'salary'] = 32000\n",
    "diarist_df.at[96, 'salary'] = 150000\n",
    "diarist_df.at[97, 'salary'] = 76000\n",
    "diarist_df.at[99, 'salary'] = 120000\n",
    "diarist_df.at[101, 'salary'] = 50000\n",
    "diarist_df.at[102, 'salary'] = 70000\n",
    "diarist_df.at[112, 'salary'] = 115000\n",
    "diarist_df.at[114, 'salary'] = 62473\n",
    "diarist_df.at[116, 'salary'] = 110000\n",
    "diarist_df.at[119, 'salary'] = 240000\n",
    "diarist_df.at[120, 'salary'] = 104738\n",
    "diarist_df.at[121, 'salary'] = 0\n",
    "diarist_df.at[125, 'salary'] = 40000\n",
    "diarist_df.at[126, 'salary'] = 60000\n",
    "diarist_df.at[127, 'salary'] = 38264\n",
    "diarist_df.at[128, 'salary'] = 82000\n",
    "diarist_df.at[133, 'salary'] = 5000\n",
    "diarist_df.at[136, 'salary'] = 150000\n",
    "diarist_df.at[143, 'salary'] = 154000\n",
    "diarist_df.at[145, 'salary'] = 100000\n",
    "diarist_df.at[148, 'salary'] = 14856\n",
    "diarist_df.at[152, 'salary'] = 63500\n",
    "diarist_df.at[158, 'salary'] = 82500\n",
    "diarist_df.at[159, 'salary'] = 61948\n",
    "diarist_df.at[162, 'salary'] = 84300\n",
    "diarist_df.at[163, 'salary'] = 135000\n",
    "diarist_df.at[165, 'salary'] = 90000\n",
    "diarist_df.at[166, 'salary'] = 65000\n",
    "diarist_df.at[169, 'salary'] = 80000\n",
    "diarist_df.at[170, 'salary'] = 105000\n",
    "diarist_df.at[171, 'salary'] = 515000\n",
    "diarist_df.at[173, 'salary'] = 74000\n",
    "diarist_df.at[175, 'salary'] = 45000\n",
    "diarist_df.at[179, 'salary'] = 0\n",
    "diarist_df.at[180, 'salary'] = 73850\n",
    "diarist_df.at[186, 'salary'] = 31915\n",
    "diarist_df.at[187, 'salary'] = 52000\n",
    "diarist_df.at[190, 'salary'] = 108000\n",
    "diarist_df.at[192, 'salary'] = 137000\n",
    "diarist_df.at[193, 'salary'] = 89000\n",
    "diarist_df.at[194, 'salary'] = 55640\n",
    "diarist_df.at[198, 'salary'] = 111524\n",
    "diarist_df.at[201, 'salary'] = 144870\n",
    "diarist_df.at[202, 'salary'] = 210000\n",
    "diarist_df.at[204, 'salary'] = 104000\n",
    "diarist_df.at[205, 'salary'] = 80000\n",
    "diarist_df.at[209, 'salary'] = 45760\n",
    "diarist_df.at[213, 'salary'] = 180780\n",
    "diarist_df.at[214, 'salary'] = 72000\n",
    "diarist_df.at[215, 'salary'] = 133000\n",
    "diarist_df.at[217, 'salary'] = 30000\n",
    "diarist_df.at[219, 'salary'] = 77000\n",
    "diarist_df.at[221, 'salary'] = 36000\n",
    "diarist_df.at[223, 'salary'] = 61000\n",
    "diarist_df.at[224, 'salary'] = 52000\n",
    "diarist_df.at[228, 'salary'] = 115000\n",
    "diarist_df.at[229, 'salary'] = 145600\n",
    "diarist_df.at[232, 'salary'] = 280000\n",
    "diarist_df.at[238, 'salary'] = 46000\n",
    "diarist_df.at[242, 'salary'] = 20250\n",
    "diarist_df.at[248, 'salary'] = 39208\n",
    "diarist_df.at[249, 'salary'] = 43617\n",
    "diarist_df.at[251, 'salary'] = 44000\n",
    "diarist_df.at[259, 'salary'] = 120000\n",
    "diarist_df.at[260, 'salary'] = 40000\n",
    "diarist_df.at[261, 'salary'] = 20840\n",
    "diarist_df.at[262, 'salary'] = 59925\n",
    "diarist_df.at[264, 'salary'] = 149000\n",
    "diarist_df.at[272, 'salary'] = 285000\n",
    "diarist_df.at[274, 'salary'] = 42000\n",
    "diarist_df.at[276, 'salary'] = 96400\n",
    "diarist_df.at[277, 'salary'] = 170000\n",
    "diarist_df.at[280, 'salary'] = 62000\n",
    "diarist_df.at[284, 'salary'] = 64000\n",
    "diarist_df.at[287, 'salary'] = 100000\n",
    "diarist_df.at[292, 'salary'] = 180000\n",
    "diarist_df.at[297, 'salary'] = 52827\n",
    "diarist_df.at[298, 'salary'] = 85000\n",
    "diarist_df.at[299, 'salary'] = 208800\n",
    "diarist_df.at[300, 'salary'] = 200000\n",
    "diarist_df.at[301, 'salary'] = 125000\n",
    "diarist_df.at[302, 'salary'] = 34500\n",
    "diarist_df.at[304, 'salary'] = 70000\n",
    "diarist_df.at[307, 'salary'] = 70000\n",
    "diarist_df.at[308, 'salary'] = 37440\n",
    "diarist_df.at[311, 'salary'] = 52817\n",
    "diarist_df.at[312, 'salary'] = 122600\n",
    "diarist_df.at[315, 'salary'] = 51500\n",
    "diarist_df.at[328, 'salary'] = 120000\n",
    "diarist_df.at[329, 'salary'] = 92400\n",
    "diarist_df.at[330, 'salary'] = 50000\n",
    "diarist_df.at[331, 'salary'] = 155000\n",
    "diarist_df.at[332, 'salary'] = 33280\n",
    "diarist_df.at[333, 'salary'] = 41600\n",
    "diarist_df.at[344, 'salary'] = 49000\n",
    "diarist_df.at[346, 'salary'] = 26000\n",
    "diarist_df.at[347, 'salary'] = 94330\n",
    "diarist_df.at[348, 'salary'] = 23000\n",
    "diarist_df.at[349, 'salary'] = 100000\n",
    "diarist_df.at[350, 'salary'] = 35360\n",
    "diarist_df.at[355, 'salary'] = 26808\n",
    "diarist_df.at[357, 'salary'] = 78000\n",
    "diarist_df.at[358, 'salary'] = 52500\n",
    "diarist_df.at[359, 'salary'] = 30000\n",
    "diarist_df.at[360, 'salary'] = 150000\n",
    "diarist_df.at[364, 'salary'] = 52000\n",
    "diarist_df.at[366, 'salary'] = 56000\n",
    "diarist_df.at[367, 'salary'] = 167000\n",
    "diarist_df.at[371, 'salary'] = 72000\n",
    "diarist_df.at[377, 'salary'] = 75000\n",
    "diarist_df.at[384, 'salary'] = 15000\n",
    "diarist_df.at[387, 'salary'] = 110000\n",
    "diarist_df.at[390, 'salary'] = 34376\n",
    "diarist_df.at[392, 'salary'] = 115900\n",
    "diarist_df.at[397, 'salary'] = 57200\n",
    "diarist_df.at[408, 'salary'] = 194000\n",
    "diarist_df.at[414, 'salary'] = 200000\n",
    "diarist_df.at[417, 'salary'] = 120000\n",
    "diarist_df.at[424, 'salary'] = 54000\n",
    "diarist_df.at[426, 'salary'] = 34216\n",
    "diarist_df.at[432, 'salary'] = 48000\n",
    "diarist_df.at[439, 'salary'] = 80000\n",
    "diarist_df.at[444, 'salary'] = 45645\n",
    "diarist_df.at[450, 'salary'] = 20000\n",
    "diarist_df.at[452, 'salary'] = 120000\n",
    "diarist_df.at[456, 'salary'] = 21419\n",
    "diarist_df.at[457, 'salary'] = 125000\n",
    "diarist_df.at[461, 'salary'] = 85500\n",
    "diarist_df.at[481, 'salary'] = 30000\n",
    "diarist_df.at[487, 'salary'] = 500000\n",
    "diarist_df.at[490, 'salary'] = 32000\n",
    "diarist_df.at[495, 'salary'] = 104000\n",
    "diarist_df.at[499, 'salary'] = 115000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:08.249408Z",
     "start_time": "2020-08-20T17:56:08.242786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use Refinery29 website to fix blank salaries\n",
    "diarist_df.at[160, 'salary'] = 36255\n",
    "diarist_df.at[184, 'salary'] = 230000\n",
    "diarist_df.at[273, 'salary'] = 0\n",
    "diarist_df.at[338, 'salary'] = 37000\n",
    "diarist_df.at[339, 'salary'] = 65515\n",
    "diarist_df.at[356, 'salary'] = 128000\n",
    "diarist_df.at[361, 'salary'] = 11000\n",
    "diarist_df.at[389, 'salary'] = 123000\n",
    "diarist_df.at[406, 'salary'] = 92800\n",
    "diarist_df.at[415, 'salary'] = 85000\n",
    "diarist_df.at[421, 'salary'] = 48000\n",
    "diarist_df.at[422, 'salary'] = 55000\n",
    "diarist_df.at[428, 'salary'] = 31720\n",
    "diarist_df.at[433, 'salary'] = 44673\n",
    "diarist_df.at[434, 'salary'] = 62400\n",
    "diarist_df.at[436, 'salary'] = 86000\n",
    "diarist_df.at[448, 'salary'] = 56035\n",
    "diarist_df.at[455, 'salary'] = 10560\n",
    "diarist_df.at[458, 'salary'] = 12000\n",
    "diarist_df.at[469, 'salary'] = 61000\n",
    "diarist_df.at[485, 'salary'] = 60000\n",
    "diarist_df.at[494, 'salary'] = 44096\n",
    "diarist_df.at[498, 'salary'] = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:08.813127Z",
     "start_time": "2020-08-20T17:56:08.807782Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert salary column to numeric type\n",
    "diarist_df['salary'] = pd.to_numeric(diarist_df['salary'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:09.125543Z",
     "start_time": "2020-08-20T17:56:09.122878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Round salary column\n",
    "diarist_df.salary = diarist_df.salary.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:09.891263Z",
     "start_time": "2020-08-20T17:56:09.850387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_title</th>\n",
       "      <th>occupation</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>/en-us/project-manager-copenhagen-denmark-sala...</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>/en-us/teacher-tri-cities-wa-salary-money-diary</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>/en-us/design-engineer-san-jose-ca-salary-mone...</td>\n",
       "      <td>Design Engineer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>/en-us/nurse-leader-boston-ma-salary-money-diary</td>\n",
       "      <td>Nurse Leader</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/en-us/2020/03/9524828/remote-teacher-salary-c...</td>\n",
       "      <td>Preschool Teacher</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           story_title         occupation  age\n",
       "358  /en-us/project-manager-copenhagen-denmark-sala...    Project Manager    2\n",
       "442    /en-us/teacher-tri-cities-wa-salary-money-diary            Teacher    2\n",
       "146  /en-us/design-engineer-san-jose-ca-salary-mone...    Design Engineer    2\n",
       "310   /en-us/nurse-leader-boston-ma-salary-money-diary       Nurse Leader    2\n",
       "0    /en-us/2020/03/9524828/remote-teacher-salary-c...  Preschool Teacher    1"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "diarist_df.groupby(['story_title', 'occupation']).age.count().reset_index().sort_values('age', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:10.640437Z",
     "start_time": "2020-08-20T17:56:10.623090Z"
    }
   },
   "outputs": [],
   "source": [
    "#Remove duplicates\n",
    "diarist_df.sort_values(['story_title', 'occupation'], inplace=True, ascending=False)\n",
    "diarist_df.drop_duplicates(subset=['story_title', 'occupation'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:11.167300Z",
     "start_time": "2020-08-20T17:56:11.164651Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reset index\n",
    "diarist_df = diarist_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:11.895373Z",
     "start_time": "2020-08-20T17:56:11.884565Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean the locations in preparation for of further processing\n",
    "diarist_df.at[19, 'location'] = 'New York, NY'\n",
    "diarist_df.at[21, 'location'] = 'Los Angeles, CA'\n",
    "diarist_df.at[24, 'location'] = 'New York, NY'\n",
    "diarist_df.at[38, 'location'] = 'Boston, MA'\n",
    "diarist_df.at[62, 'location'] = 'Boston, MA'\n",
    "diarist_df.at[87, 'location'] = 'San Francisco, CA'\n",
    "diarist_df.at[107, 'location'] = 'New York, NY'\n",
    "diarist_df.at[108, 'location'] = 'San Francisco, CA'\n",
    "diarist_df.at[115, 'location'] = 'New York, NY'\n",
    "diarist_df.at[116, 'location'] = 'Philadelphia, PA'\n",
    "diarist_df.at[163, 'location'] = 'Baltimore, MD'\n",
    "diarist_df.at[235, 'location'] = 'Chicago, IL'\n",
    "diarist_df.at[243, 'location'] = 'Los Angeles, CA'\n",
    "diarist_df.at[250, 'location'] = 'New York, NY'\n",
    "diarist_df.at[258, 'location'] = 'New York, NY'\n",
    "diarist_df.at[310, 'location'] = 'Chicago, IL'\n",
    "diarist_df.at[330, 'location'] = 'Denver, CO'\n",
    "diarist_df.at[384, 'location'] = 'Chicago, IL'\n",
    "diarist_df.at[387, 'location'] = 'Chicago, IL'\n",
    "diarist_df.at[388, 'location'] = 'Chicago, IL'\n",
    "diarist_df.at[393, 'location'] = 'San Francisco, CA'\n",
    "diarist_df.at[405, 'location'] = 'Boston, MA'\n",
    "diarist_df.at[406, 'location'] = 'Boston, MA'\n",
    "diarist_df.at[422, 'location'] = 'Detroit, MI'\n",
    "diarist_df.at[429, 'location'] = 'New York, NY'\n",
    "diarist_df.at[55, 'location'] = 'Japan'\n",
    "diarist_df.at[273, 'location'] = 'Toronto'\n",
    "diarist_df.at[320, 'location'] = 'Bali, Indonesia'\n",
    "diarist_df.at[475, 'location'] = 'Chengdu, China'\n",
    "diarist_df.at[142, 'location'] = 'Canada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:12.532709Z",
     "start_time": "2020-08-20T17:56:12.526405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add nomad column (1 = nomadic living)\n",
    "nomadic_list_indices = [96, 171, 298, 431, 472]\n",
    "diarist_df['nomad'] = 0\n",
    "diarist_df.at[96, 'nomad'] = 1\n",
    "diarist_df.at[171, 'nomad'] = 1\n",
    "diarist_df.at[298, 'nomad'] = 1\n",
    "diarist_df.at[431, 'nomad'] = 1\n",
    "diarist_df.at[472, 'nomad'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:13.254688Z",
     "start_time": "2020-08-20T17:56:13.240744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add international column (1 = international living)\n",
    "outside_us_indices = [0, 15, 26, 28, 30, 35, 55, 95, 98, 99, 117, 145, 146, 149, 187, 215, 226, 229, 230, 231, 257, \n",
    "                      263, 271, 273, 286, 287, 289, 301, 302, 303, 320, 321, 337, 347, 350, 351, 395, 396, 400, 401,\n",
    "                      417, 421, 436, 454, 466, 475]\n",
    "diarist_df['international'] = 0\n",
    "diarist_df.at[0, 'international'] = 1\n",
    "diarist_df.at[15, 'international'] = 1\n",
    "diarist_df.at[26, 'international'] = 1\n",
    "diarist_df.at[28, 'international'] = 1\n",
    "diarist_df.at[30, 'international'] = 1\n",
    "diarist_df.at[35, 'international'] = 1\n",
    "diarist_df.at[55, 'international'] = 1\n",
    "diarist_df.at[95, 'international'] = 1\n",
    "diarist_df.at[98, 'international'] = 1\n",
    "diarist_df.at[99, 'international'] = 1\n",
    "diarist_df.at[117, 'international'] = 1\n",
    "diarist_df.at[145, 'international'] = 1\n",
    "diarist_df.at[146, 'international'] = 1\n",
    "diarist_df.at[149, 'international'] = 1\n",
    "diarist_df.at[187, 'international'] = 1\n",
    "diarist_df.at[215, 'international'] = 1\n",
    "diarist_df.at[226, 'international'] = 1\n",
    "diarist_df.at[229, 'international'] = 1\n",
    "diarist_df.at[230, 'international'] = 1\n",
    "diarist_df.at[231, 'international'] = 1\n",
    "diarist_df.at[257, 'international'] = 1\n",
    "diarist_df.at[263, 'international'] = 1\n",
    "diarist_df.at[271, 'international'] = 1\n",
    "diarist_df.at[273, 'international'] = 1\n",
    "diarist_df.at[286, 'international'] = 1\n",
    "diarist_df.at[287, 'international'] = 1\n",
    "diarist_df.at[289, 'international'] = 1\n",
    "diarist_df.at[301, 'international'] = 1\n",
    "diarist_df.at[302, 'international'] = 1\n",
    "diarist_df.at[303, 'international'] = 1\n",
    "diarist_df.at[320, 'international'] = 1\n",
    "diarist_df.at[321, 'international'] = 1\n",
    "diarist_df.at[337, 'international'] = 1\n",
    "diarist_df.at[347, 'international'] = 1\n",
    "diarist_df.at[350, 'international'] = 1\n",
    "diarist_df.at[351, 'international'] = 1\n",
    "diarist_df.at[395, 'international'] = 1\n",
    "diarist_df.at[396, 'international'] = 1\n",
    "diarist_df.at[400, 'international'] = 1\n",
    "diarist_df.at[401, 'international'] = 1\n",
    "diarist_df.at[417, 'international'] = 1\n",
    "diarist_df.at[421, 'international'] = 1\n",
    "diarist_df.at[436, 'international'] = 1\n",
    "diarist_df.at[454, 'international'] = 1\n",
    "diarist_df.at[466, 'international'] = 1\n",
    "diarist_df.at[475, 'international'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:13.716571Z",
     "start_time": "2020-08-20T17:56:13.700898Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code cities in high cost of living areas as 1 (from: https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population)\n",
    "major_city_list_abbreviation = ['New York, NY', 'Los Angeles, CA', 'Chicago, IL', 'Houston, TX', 'Phoenix, AZ', 'Philadelphia, PA',\n",
    "                   'San Antonio, TX', 'Dallas, TX', 'San Jose, CA', 'Austin, TX', 'Jacksonville, FL', 'Fort Worth, TX',\n",
    "                  'Columbus, OH', 'Charlotte, NC', 'San Francisco, CA', 'Indianapolis, IN', 'Seattle, WA', 'Denver, CO',\n",
    "                  'Washington, DC', 'Boston, MA', 'El Paso, TX', 'Nashville, TN', 'Detroit, MI', 'Oklahoma City, OK']\n",
    "\n",
    "major_city_list_full_state = ['New York, New York', 'Los Angeles, California', 'Chicago, Illinois', 'Houston, Texas', 'Phoenix, Arizona', 'Philadelphia, PA',\n",
    "                   'San Antonio, Texas', 'Dallas, Texas', 'San Jose, California', 'Austin, Texas', 'Jacksonville, Florida', 'Fort Worth, Texas',\n",
    "                  'Columbus, Ohio', 'Charlotte, North Carolina', 'San Francisco, California', 'Indianapolis, Indiana', 'Seattle, Washington', 'Denver, Colorado',\n",
    "                  'Washington DC', 'Boston, Massachusetts', 'El Paso, Texas', 'Nashville, Tennessee', 'Detroit, Michigan', 'Oklahoma City, Oklahoma']\n",
    "\n",
    "other_names_for_ny = ['Brooklyn, NY', 'Queens, NY', 'Manhattan, NY']\n",
    "\n",
    "def in_major_city(location):\n",
    "    \"Takes in a location and returns a value of 0 or 1 if the input location is in one of the lists\"\n",
    "    if (location in major_city_list_abbreviation) or (location in major_city_list_full_state)  or (location in other_names_for_ny):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "diarist_df['high_cost_of_living_area'] = diarist_df.apply(lambda x: in_major_city(x['location']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:14.798028Z",
     "start_time": "2020-08-20T17:56:14.791131Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "diarist_df.drop(columns=['location', 'net_worth', 'debt', 'rent', 'mortgage', 'loans', 'savings'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:15.444805Z",
     "start_time": "2020-08-20T17:56:15.434722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_title</th>\n",
       "      <th>occupation</th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>nomad</th>\n",
       "      <th>international</th>\n",
       "      <th>high_cost_of_living_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>/en-us/associate-publicist-new-york-salary-mon...</td>\n",
       "      <td>Associate Publicist</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           story_title           occupation  \\\n",
       "433  /en-us/associate-publicist-new-york-salary-mon...  Associate Publicist   \n",
       "\n",
       "    age  salary  nomad  international  high_cost_of_living_area  \n",
       "433  27     NaN      0              0                         1  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check for null values & fill\n",
    "diarist_df[diarist_df.salary.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:19.368353Z",
     "start_time": "2020-08-20T17:56:19.366104Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill last null value using Refinery29 website\n",
    "diarist_df.at[433, 'salary'] = 44673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:57:28.655574Z",
     "start_time": "2020-08-20T17:57:28.652717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert age to int\n",
    "diarist_df.age = diarist_df.age.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T17:56:19.913279Z",
     "start_time": "2020-08-20T17:56:19.906593Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Pickle cleaned diarist_df\n",
    "# with open('diarist_df_updated.pkl', 'wb') as f:\n",
    "#     pickle.dump(diarist_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T22:20:51.989870Z",
     "start_time": "2020-08-18T22:20:51.985543Z"
    }
   },
   "source": [
    "**Clean text_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T22:33:33.093366Z",
     "start_time": "2020-08-18T22:33:33.039214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the diary text column from a list to a string\n",
    "text_df['diary_text_string'] = [', '.join(map(str, l)) for l in text_df['diary_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T22:33:44.530270Z",
     "start_time": "2020-08-18T22:33:44.526953Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the diary_text as list column\n",
    "del text_df['diary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T22:38:30.750734Z",
     "start_time": "2020-08-18T22:38:30.743464Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge diarist_df with text_df \n",
    "updated_text_df = pd.merge(diarist_df, text_df, left_on='story_title', right_on='story_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T22:40:13.820552Z",
     "start_time": "2020-08-18T22:40:13.816459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop all columns but link and diary text from updated_text_df\n",
    "updated_text_df.drop(columns=['occupation', 'age', 'salary', 'nomad', 'international', 'high_cost_of_living_area'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T22:41:31.209340Z",
     "start_time": "2020-08-18T22:41:31.204207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply a first round of text cleaning techniques\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation, remove words \n",
    "    containing numbers, remove additional punctuation and other non-sensical text.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(' — ',' ', text)      #attempts to remove hyphen\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)   #removes numbers\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('^', '', text)\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-18T22:41:32.904923Z",
     "start_time": "2020-08-18T22:41:31.517698Z"
    }
   },
   "outputs": [],
   "source": [
    "data_clean = pd.DataFrame(updated_text_df.diary_text_string.apply(round1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T00:11:59.283400Z",
     "start_time": "2020-08-19T00:11:59.238720Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Pickle cleaned text data\n",
    "# with open('data_clean.pkl', 'wb') as f:\n",
    "#     pickle.dump(data_clean, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
